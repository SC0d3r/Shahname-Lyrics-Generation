{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit"
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "colab": {
      "name": "Shahname-LSTM-Word.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import time"
      ],
      "outputs": [],
      "metadata": {
        "id": "E0b7zpINjymN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# get all train texts\n",
        "dir = \"../\"\n",
        "train_texts = \"\"\n",
        "files = os.listdir(dir + \"shahname/train\")\n",
        "for path in files:\n",
        "\ttrain_texts += open(dir + \"shahname/train/\" + path, 'rb').read().decode(encoding='utf-8')"
      ],
      "outputs": [],
      "metadata": {
        "id": "J_4TTslLjymR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "source": [
        "file_text = open(dir + \"allShahnameWords.txt\", 'rb').read().decode(encoding = \"utf-8\")\n",
        "vocab = file_text.split(\"\\n\")\n",
        "\n",
        "# vocab = sorted(set(file_text))\n",
        "vocab.append(\" \")\n",
        "# vocab.append(\"\\n\")\n",
        "\n",
        "ids_from_words = preprocessing.StringLookup(\n",
        "    vocabulary=vocab, mask_token=None)\n",
        "# print(vocab[20])\n",
        "# a= ids_from_words(\"اباپیل\")\n",
        "# a"
      ],
      "outputs": [],
      "metadata": {
        "id": "EaenmT5WjymR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "source": [
        "tf.strings.split(train_texts)[50].numpy().decode(\"utf-8\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'کاخ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "H_r0oOquzH97",
        "outputId": "9a479dbc-7bf8-4084-8072-828ed10fc9c2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "source": [
        "# turn ids into human readable text\n",
        "\n",
        "words_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_words.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(words_from_ids(ids))#, axis=-1)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "f-aIVeY3jymU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "source": [
        "all_ids = ids_from_words(tf.strings.split(train_texts))#tf.strings.unicode_split(train_texts, 'UTF-8'))\n",
        "all_ids"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(533516,), dtype=int64, numpy=array([ 8494, 10084,   390, ...,  8494, 11220,  6646])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB-AIVJJjymV",
        "outputId": "61252059-9922-4234-9cbf-614d83e05d45"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "source": [
        "# all_ids[0].numpy()\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "\n",
        "for ids in ids_dataset.take(10):\n",
        "    print(words_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "چو\n",
            "دشت\n",
            "از\n",
            "گیا\n",
            "گشت\n",
            "چون\n",
            "پرنیان\n",
            "ببستند\n",
            "گردان\n",
            "توران\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnDSUF4pjymW",
        "outputId": "1d86b8ad-7927-48e8-d1a3-381b55bec91c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(train_texts)//(seq_length+1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SaSxK9JTjymX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  tmp = words_from_ids(seq).numpy()\n",
        "  print(''.join([str(s, encoding='UTF-8') for s in tmp]))\n",
        "  # print(chars_from_ids(seq))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "چودشتازگیاگشتچونپرنیانببستندگردانتورانمیانسپاهیبیامدزترکانوچینهمازگرزدارانخاورزمینکهآنرامیانوکرانهنبودهمانبختنوذرجوانهنبودچولشکربهنزدیکجیحونرسیدخبرنزدپورفریدونرسیدسپاهجهانداربیرونشدندزکاخهمایونبههامونشدندبهراهدهستاننهادندرویسپهدارشانقارنرزم‌جویشهنشاهنوذرپسپشتاویجهانیسراسرپرازگفتوگویچولشکربهپیشدهستانرسیدتوگفتیکهخورشیدشدناپدیدسراپردهٔنوذرشهریارکشیدندبردشتپیشحصارخوداندردهستاننیاراستجنگبرین\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dq68MGhjymY",
        "outputId": "01f549b3-3804-4c9b-8b68-fbb1d01b983f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy().decode(\"utf-8\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "چودشتازگیاگشتچونپرنیانببستندگردانتورانمیانسپاهیبیامدزترکانوچینهمازگرزدارانخاورزمینکهآنرامیانوکرانهنبودهمانبختنوذرجوانهنبودچولشکربهنزدیکجیحونرسیدخبرنزدپورفریدونرسیدسپاهجهانداربیرونشدندزکاخهمایونبههامونشدندبهراهدهستاننهادندرویسپهدارشانقارنرزم‌جویشهنشاهنوذرپسپشتاویجهانیسراسرپرازگفتوگویچولشکربهپیشدهستانرسیدتوگفتیکهخورشیدشدناپدیدسراپردهٔنوذرشهریارکشیدندبردشتپیشحصارخوداندردهستاننیاراستجنگبرین\n",
            "برنیامدزمانیدرنگکهافراسیاباندرایرانزمیندوسالارکردازبزرگانگزینشماساسودیگرخزروانگردزلشکرسوارانبدیشانسپردزجنگآورانمردچونسیهزاربرفتندشایستهٔکارزارسویزابلستاننهادندرویزکینهبهدستاننهادندرویخبرشدکهسامنریمانبمردهمیدخمهسازدورازالگردازانسختشادانشدافراسیاببدیدآنکهبختاندرآمدبهخواببیامدچوپیشدهستانرسیدبرابرسراپرده‌ایبرکشیدسپهراکهدانستکردنشماربروچارصدباربشمرهزاربجوشیدگفتیهمهریگوشخبیابانسراسرچوموروملخابا\n",
            "شاهنوذرصدوچلهزارهماناکهبودندجنگیسواربهلشکرنگهکردافراسیابهیونیبرافگندهنگامخوابیکینامهبنوشتسویپشنگکهجستیمنیکیوآمدبهچنگهمهلشکرنوذراربشکریمشکارندودرزیرپیبسپریمدگرسامرفتازدرشهریارهمانانیایدبدینکارزارستودانهمیسازدشزالزرنداردهمیجنگراپایوپرمرابیمازوبدبهایرانزمینچواوشدزایرانبجوییمکینهماناشماساسدرنیمروزنشستستباتاجگیتیفروزبههنگامهرکارجستننکوستزدنرایبامردهشیارودوست\n",
            "چوکاهلشودمردهنگامکارازانپسنیابدچنانروزگارهیونتکاوربرآوردپربشدنزدسالارخورشیدفرزمانیپراندیشهشدزالزربرآوردیالوبگستردبروزانپسبهپاسخزبانبرگشادهمهپرسشموبدانکردیادنخستازدهودودرختبلندکههریکهمیشاخسیبرکشندبهسالیدهودوبودماهنوچوشاهنوآیینابرگاهنوبهسیروزمهراسرآیدشماربرینسانبودگردشروزگارکنونآنکهگفتیزکاردواسپفروزانبهکردارآذرگشسپسپیدوسیاهستهردوزمانپس\n",
            "یکدگرتیزهردودوانشبوروزباشدکهمی‌بگذرددمچرخبرماهمیبشمردسدیگرکهگفتیکهآنسیسوارکجابرگذشتندبرشهریارازانسیسوارانیکیکمشودبهگاهشمردنهمانسیبودنگفتیسخنجززنقصانماهکهیکشبکمآیدهمیگاهگاهکنونازنیاماینسخنبرکشیمدوبنسروکانمرغداردنشیمزبرجبرهتاترازوجهانهمیتیرگیدارداندرنهانچنینتازگردشبهماهیشودپرازتیرگیوسیاهیشوددوسروایدوبازویچرخبلندکزونیمهشادب\n"
          ]
        }
      ],
      "metadata": {
        "id": "BaViEcI4jymY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b11762-7373-446e-da8e-78743eb4bef8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9f-oNCA5jymZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy().decode(\"utf-8\"))\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy().decode(\"utf-8\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : چودشتازگیاگشتچونپرنیانببستندگردانتورانمیانسپاهیبیامدزترکانوچینهمازگرزدارانخاورزمینکهآنرامیانوکرانهنبودهمانبختنوذرجوانهنبودچولشکربهنزدیکجیحونرسیدخبرنزدپورفریدونرسیدسپاهجهانداربیرونشدندزکاخهمایونبههامونشدندبهراهدهستاننهادندرویسپهدارشانقارنرزم‌جویشهنشاهنوذرپسپشتاویجهانیسراسرپرازگفتوگویچولشکربهپیشدهستانرسیدتوگفتیکهخورشیدشدناپدیدسراپردهٔنوذرشهریارکشیدندبردشتپیشحصارخوداندردهستاننیاراستجنگ\n",
            "Target: دشتازگیاگشتچونپرنیانببستندگردانتورانمیانسپاهیبیامدزترکانوچینهمازگرزدارانخاورزمینکهآنرامیانوکرانهنبودهمانبختنوذرجوانهنبودچولشکربهنزدیکجیحونرسیدخبرنزدپورفریدونرسیدسپاهجهانداربیرونشدندزکاخهمایونبههامونشدندبهراهدهستاننهادندرویسپهدارشانقارنرزم‌جویشهنشاهنوذرپسپشتاویجهانیسراسرپرازگفتوگویچولشکربهپیشدهستانرسیدتوگفتیکهخورشیدشدناپدیدسراپردهٔنوذرشهریارکشیدندبردشتپیشحصارخوداندردهستاننیاراستجنگبرین\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSPkUUTRjyma",
        "outputId": "489653f2-34d8-4eb2-fb21-a655f21718c4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgDXp_gqjyma",
        "outputId": "7967c8de-3f8f-4114-c984-03425ad1d4ec"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "source": [
        "# Model\n",
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.LSTM(rnn_units,\n",
        "                                    #stateful=True \n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True\n",
        "    )\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      h_state, c_state = self.gru.get_initial_state(x)\n",
        "    else:\n",
        "      h_state, c_state = states\n",
        "    #x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x, h_state,c_state = self.gru(x, initial_state=[h_state,c_state], training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, h_state, c_state\n",
        "    else:\n",
        "      return x"
      ],
      "outputs": [],
      "metadata": {
        "id": "sjG8m1iGjymb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "source": [
        "vocab_size"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSD96Xu5oMLD",
        "outputId": "32e58872-6792-4c03-be39-27f8d04d2a55"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_words.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "outputs": [],
      "metadata": {
        "id": "t88cB1ohjymc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 19778) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7VfEmPKjymd",
        "outputId": "a85cf4ff-37c4-4371-925a-7e5899d67ce0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "source": [
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      multiple                  5063168   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                multiple                  5246976   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  20272450  \n",
            "=================================================================\n",
            "Total params: 30,582,594\n",
            "Trainable params: 30,582,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEPnjdCjjyme",
        "outputId": "96ed4825-5e3f-471f-945f-06d11080d390"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "source": [
        "# Befor training\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 19778)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         9.892313\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_ugyQYQjyme",
        "outputId": "3bd1cce2-ce41-4ffe-d06a-679e44e5ce42"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "source": [
        "tf.exp(mean_loss).numpy()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19777.752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhX59Bi-jymf",
        "outputId": "77d5febe-846c-4246-cc9a-f3ec85041a3e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7Z6z39BEjymf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Oi6nfb7Mjymg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "source": [
        "EPOCHS = 30\n",
        "history = model.fit(dataset, epochs=EPOCHS)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "82/82 [==============================] - 28s 320ms/step - loss: 7.6073\n",
            "Epoch 2/30\n",
            "82/82 [==============================] - 28s 334ms/step - loss: 7.2250\n",
            "Epoch 3/30\n",
            "82/82 [==============================] - 28s 333ms/step - loss: 7.1333\n",
            "Epoch 4/30\n",
            "82/82 [==============================] - 27s 328ms/step - loss: 6.9167\n",
            "Epoch 5/30\n",
            "82/82 [==============================] - 28s 336ms/step - loss: 6.7314\n",
            "Epoch 6/30\n",
            "82/82 [==============================] - 29s 339ms/step - loss: 6.5451\n",
            "Epoch 7/30\n",
            "82/82 [==============================] - 28s 335ms/step - loss: 6.3184\n",
            "Epoch 8/30\n",
            "82/82 [==============================] - 28s 332ms/step - loss: 6.0864\n",
            "Epoch 9/30\n",
            "82/82 [==============================] - 28s 339ms/step - loss: 5.8659\n",
            "Epoch 10/30\n",
            "82/82 [==============================] - 29s 341ms/step - loss: 5.6563\n",
            "Epoch 11/30\n",
            "82/82 [==============================] - 28s 335ms/step - loss: 5.4638\n",
            "Epoch 12/30\n",
            "82/82 [==============================] - 28s 334ms/step - loss: 5.2962\n",
            "Epoch 13/30\n",
            "82/82 [==============================] - 28s 338ms/step - loss: 5.1451\n",
            "Epoch 14/30\n",
            "82/82 [==============================] - 28s 332ms/step - loss: 5.0103\n",
            "Epoch 15/30\n",
            "82/82 [==============================] - 28s 333ms/step - loss: 4.8852\n",
            "Epoch 16/30\n",
            "82/82 [==============================] - 28s 337ms/step - loss: 4.7677\n",
            "Epoch 17/30\n",
            "82/82 [==============================] - 28s 336ms/step - loss: 4.6591\n",
            "Epoch 18/30\n",
            "82/82 [==============================] - 28s 336ms/step - loss: 4.5536\n",
            "Epoch 19/30\n",
            "82/82 [==============================] - 28s 336ms/step - loss: 4.4555\n",
            "Epoch 20/30\n",
            "82/82 [==============================] - 28s 335ms/step - loss: 4.3608\n",
            "Epoch 21/30\n",
            "82/82 [==============================] - 28s 340ms/step - loss: 4.2677\n",
            "Epoch 22/30\n",
            "82/82 [==============================] - 28s 333ms/step - loss: 4.1804\n",
            "Epoch 23/30\n",
            "82/82 [==============================] - 28s 334ms/step - loss: 4.0957\n",
            "Epoch 24/30\n",
            "82/82 [==============================] - 28s 332ms/step - loss: 4.0135\n",
            "Epoch 25/30\n",
            "82/82 [==============================] - 28s 334ms/step - loss: 3.9340\n",
            "Epoch 26/30\n",
            "82/82 [==============================] - 28s 333ms/step - loss: 3.8568\n",
            "Epoch 27/30\n",
            "82/82 [==============================] - 28s 331ms/step - loss: 3.7831\n",
            "Epoch 28/30\n",
            "82/82 [==============================] - 28s 330ms/step - loss: 3.7115\n",
            "Epoch 29/30\n",
            "82/82 [==============================] - 27s 326ms/step - loss: 3.6405\n",
            "Epoch 30/30\n",
            "82/82 [==============================] - 28s 333ms/step - loss: 3.5731\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q1Bk7_fjymg",
        "outputId": "bbf49511-44de-40de-f007-59d58aeccfdb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "source": [
        "# Save model\n",
        "save_dir = \"model-word-v1.h5\"\n",
        "# model.save_weights(save_dir)  # to store\n",
        "\n",
        "# Load model\n",
        "model.load_weights(save_dir)  # to load"
      ],
      "outputs": [],
      "metadata": {
        "id": "wMZplVa8-aZo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # h_state, c_state = states\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, h_state, c_state = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, h_state, c_state"
      ],
      "outputs": [],
      "metadata": {
        "id": "WmbUFQAyjymg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy().decode(\"utf-8\"))\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy().decode(\"utf-8\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " ندیدبرونامشاهیواوناپدیدصدمسالروزیبهدریایچینپدیدآمدآنشاهناپاکدیننهانگشتهبودازبداژدهانیامدبهفرجامهمزورهاچوضحاکشآوردناگهبهچنگیکایکندادشزمانیدرنگبهارشسراسربهدونیمکردجهانراازوپاکبی‌بیمکردشدآنتختشاهیوآندستگاهزمانهربودشچوبیجادهکاهازوبیشبرتختشاهیکهبودبرانرنجبردنچهآمدشسودگذشتهبروسالیانهفتصدپدیدآوریدههمهنیکوبدچهبایدهمهزندگانیدرازچوگیتینخواهدگشادنترازهمی\n",
            "\n",
            "Next Char Predictions:\n",
            " چمیدنشرابسروربرخواربوسخورهٔبنوککمترمپیروزه،نفتنوش‌لبغرندهجهانبانقیصرمستبرستپایانبپرسندهوبستهوپیوندپرده‌داراسپیبپساورامخوانیدشتابنده‌اندوبنشاهنشاهانمگرشانپیلبازیمردارچارپایانوبشادینیابیمچاکریگوهرشناسلشکری‌دارچنگقندگریختبی‌بارسپاربدانچتشهمزسیدادییمگذاردادخواهندگانومغزیخرمپیداستوبرآسیمهبی‌غمبرداشتیدشارستانگزینندورازاداندرونشآسانیبکشتمپیل‌بازیوکامجویستکهترایارایزکسریبخوابیدکنابدبرکمسرانجمنیالگشودافگندپولادبرزشیربرخواندمبامشآبگیریشهشبخوربیدنشناختندویرانیراگشادنخرامیدمبخورشیدوماهپای‌بندفرودینازنوشبدکمنشببارغرمکرده‌ایدگرایندجسمبیرنجرزم‌زنخواندتدرندهمرزمدرگرفتازلشکری\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVgps8Zijymi",
        "outputId": "60f10075-7f0a-464c-80b2-48ed6d49a59b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "source": [
        "one_step_model = OneStep(model, words_from_ids, ids_from_words)"
      ],
      "outputs": [],
      "metadata": {
        "id": "fCW4Mpe1jymi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate fake texts"
      ],
      "metadata": {
        "id": "laEQPBNrjymi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "source": [
        "start = time.time()\n",
        "next_char = tf.constant(['مرا گفت کاین نامهٔ شهریار'])\n",
        "states = None\n",
        "zero_out = tf.keras.layers.Lambda(lambda x: tf.zeros_like(x))(next_char)\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(30):\n",
        "  next_char, h_state, c_state = one_step_model.generate_one_step(next_char, states=states)\n",
        "  states = [h_state, c_state]\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result,\" \")\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'))\n",
        "print('\\nRun time:', end - start)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مرا گفت کاین نامهٔ شهریار نیست بگفت پاک باشد مرد گر بود گر شد مرد که پاک باشد ما نداریم بود بپیش پاک داری نگار جهان پاک باید اژدهاست آفریننده‌ام پاک هست پاک فرمان پاک\n",
            "\n",
            "Run time: 0.11357998847961426\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6L73OIhjymj",
        "outputId": "48292811-b822-4a09-8d70-1b580fc71ac3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generated texts\n",
        "\n",
        "> مرا گفت کاین نامهٔ شهریار\n",
        "\n",
        "> نیست بگفت پاک باشد مرد گر بود\n",
        "\n",
        ">  گر شد مرد که پاک باشد ما نداریم \n",
        "\n",
        "> بود بپیش پاک داری نگار جهان پاک\n"
      ],
      "metadata": {
        "id": "pTDsTzngrrOj"
      }
    }
  ]
}