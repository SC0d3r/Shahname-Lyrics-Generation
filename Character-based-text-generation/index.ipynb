{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit"
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "colab": {
      "name": "Shahname-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import time"
      ],
      "outputs": [],
      "metadata": {
        "id": "E0b7zpINjymN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# get all train texts\n",
        "dir = \"../\"\n",
        "train_texts = \"\"\n",
        "files = os.listdir(dir + \"shahname/train\")\n",
        "for path in files:\n",
        "\ttrain_texts += open(dir + \"shahname/train/\" + path, 'rb').read().decode(encoding='utf-8')"
      ],
      "outputs": [],
      "metadata": {
        "id": "J_4TTslLjymR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "file_text = open(dir + \"allShahnameWords.txt\", 'rb').read().decode(encoding = \"utf-8\")\n",
        "vocab = sorted(set(file_text))\n",
        "vocab.append(\" \")\n",
        "\n",
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ],
      "outputs": [],
      "metadata": {
        "id": "EaenmT5WjymR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# turn ids into human readable text\n",
        "\n",
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "f-aIVeY3jymU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(train_texts, 'UTF-8'))\n",
        "all_ids"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2426146,), dtype=int64, numpy=array([41, 38, 47, ..., 36, 20,  1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB-AIVJJjymV",
        "outputId": "76f26a36-b035-4209-914b-9f81b2893170"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "\n",
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "چ\n",
            "و\n",
            " \n",
            "د\n",
            "ش\n",
            "ت\n",
            " \n",
            "ا\n",
            "ز\n",
            " \n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnDSUF4pjymW",
        "outputId": "b6aa6342-6a16-454c-9204-658413de8226"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(train_texts)//(seq_length+1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SaSxK9JTjymX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  tmp = chars_from_ids(seq).numpy()\n",
        "  print(''.join([str(s, encoding='UTF-8') for s in tmp]))\n",
        "  # print(chars_from_ids(seq))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "چو دشت از گیا گشت چون پرنیان[UNK]ببستند گردان توران میان\n",
            "سپاهی بیامد ز ترکان و چین[UNK]هم از گرزداران خاور زم\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dq68MGhjymY",
        "outputId": "7c75a2d5-45fb-4c32-9ae6-9f71e7a7e44b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy().decode(\"utf-8\"))"
      ],
      "outputs": [],
      "metadata": {
        "id": "BaViEcI4jymY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9f-oNCA5jymZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy().decode(\"utf-8\"))\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy().decode(\"utf-8\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : چو دشت از گیا گشت چون پرنیان[UNK]ببستند گردان توران میان\n",
            "سپاهی بیامد ز ترکان و چین[UNK]هم از گرزداران خاور ز\n",
            "Target: و دشت از گیا گشت چون پرنیان[UNK]ببستند گردان توران میان\n",
            "سپاهی بیامد ز ترکان و چین[UNK]هم از گرزداران خاور زم\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSPkUUTRjyma",
        "outputId": "8eebdd84-b20f-470e-c8dc-6bf2ce875c0c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgDXp_gqjyma",
        "outputId": "f9f478bf-e877-4ec2-a56c-23a1d0861da7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Model\n",
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.LSTM(rnn_units,\n",
        "                                    #stateful=True \n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True\n",
        "    )\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      h_state, c_state = self.gru.get_initial_state(x)\n",
        "    else:\n",
        "      h_state, c_state = states\n",
        "    #x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x, h_state,c_state = self.gru(x, initial_state=[h_state,c_state], training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, h_state, c_state\n",
        "    else:\n",
        "      return x"
      ],
      "outputs": [],
      "metadata": {
        "id": "sjG8m1iGjymb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vocab_size"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "fSD96Xu5oMLD",
        "outputId": "dba46d8b-437f-4f9a-ca48-75375c75ba26"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "outputs": [],
      "metadata": {
        "id": "t88cB1ohjymc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 48) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7VfEmPKjymd",
        "outputId": "d7f7e512-38a3-4e70-8ef3-8d97a56d0aaf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      multiple                  12288     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                multiple                  5246976   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  49200     \n",
            "=================================================================\n",
            "Total params: 5,308,464\n",
            "Trainable params: 5,308,464\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEPnjdCjjyme",
        "outputId": "cbf2ebdf-a50e-4a52-fb43-3d606ce11212"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Befor training\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 48)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         3.8723047\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_ugyQYQjyme",
        "outputId": "6d1149b0-664d-4959-9c5f-2fb7fdfdf96f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tf.exp(mean_loss).numpy()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48.053005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhX59Bi-jymf",
        "outputId": "910aa8fd-51e2-404d-910a-7e473a883937"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7Z6z39BEjymf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Oi6nfb7Mjymg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "EPOCHS = 1\n",
        "history = model.fit(dataset, epochs=EPOCHS)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 27s 67ms/step - loss: 0.4635\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q1Bk7_fjymg",
        "outputId": "d99d8c57-008a-439a-b642-524f09a8f9c9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Save model\n",
        "save_dir = \"model-char-v3.h5\"\n",
        "# model.save_weights(save_dir)  # to store\n",
        "\n",
        "# Load model\n",
        "model.load_weights(save_dir)  # to load"
      ],
      "outputs": [],
      "metadata": {
        "id": "wMZplVa8-aZo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # h_state, c_state = states\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, h_state, c_state = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, h_state, c_state"
      ],
      "outputs": [],
      "metadata": {
        "id": "WmbUFQAyjymg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy().decode(\"utf-8\"))\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy().decode(\"utf-8\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " ار باشد مرا نیک‌بخت\n",
            "هرانگه که آید گمانتان که من[UNK]رسیدم بدان پاک‌رای انجمن\n",
            "غو دیده باید که از دیدگاه[UNK]ک\n",
            "\n",
            "Next Char Predictions:\n",
            " ءچؤزدضظشکی غءزشواشحغثامیشذذذ»ءٔیژؤ[UNK])تئؤ،رصکبکضنج؟ءذش«عپشخژأگءدؤ[UNK]عظط«ئحس( ‌ أ\n",
            "ضدأا »نقضغپ)ء(نء»کؤ)چ؟ز\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVgps8Zijymi",
        "outputId": "eeaa448a-f007-4e9c-c012-de50abcbaa87"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "outputs": [],
      "metadata": {
        "id": "fCW4Mpe1jymi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate fake texts"
      ],
      "metadata": {
        "id": "laEQPBNrjymi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "start = time.time()\n",
        "next_char = tf.constant(['هم‌اندر زمان لشکر آنجا رسید'])\n",
        "states = None\n",
        "zero_out = tf.keras.layers.Lambda(lambda x: tf.zeros_like(x))(next_char)\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(120):\n",
        "  next_char, h_state, c_state = one_step_model.generate_one_step(next_char, states=states)\n",
        "  states = [h_state, c_state]\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "هم‌اندر زمان لشکر آنجا رسید\n",
            "هشیوار دستور پستان کنید\n",
            "دلیران هوا باز داده بدوخت\n",
            "بشد با کبان درد و فرشیدوردبارد اندر هواست\n",
            "چو آمد بنزدیک آن برکنند\n",
            "تو  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 1.1943893432617188\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6L73OIhjymj",
        "outputId": "c0d16171-d2d7-4c78-f2a9-53c8f6e2ba31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generated texts\n",
        "\n",
        "> بگرییم چندی بران رزمگاه\n",
        "\n",
        "> بدو گفت موبد که ای شهریار\n",
        "\n",
        "\n",
        "> توایم چرا با چنین یک زمانه همیوست ماه\n",
        "\n",
        "> شمار سپاه اندر آید ز جای"
      ],
      "metadata": {
        "id": "pTDsTzngrrOj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "trvDjnnCr4Rn"
      }
    }
  ]
}